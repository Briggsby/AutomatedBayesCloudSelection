\addvspace {10\p@ }
\addvspace {10\p@ }
\addvspace {10\p@ }
\addvspace {10\p@ }
\contentsline {figure}{\numberline {4.1}{\ignorespaces A flowchart showing the processes involved in and information flow through the designed system.}}{19}{figure.4.1}% 
\addvspace {10\p@ }
\contentsline {figure}{\numberline {5.1}{\ignorespaces An example of BO's working process. Taken from Figure 5 in \cite {Alipourfard2017}}}{26}{figure.5.1}% 
\addvspace {10\p@ }
\addvspace {10\p@ }
\contentsline {figure}{\numberline {7.1}{\ignorespaces Boxplots showing the distribution of vBench scores and objective measure values (both plotted on y-axis, different scales), varied across different machines, differentiated by cloud provider (colour), instance category (columns), and number of vCPUs (x axis). vBench benchmark was run using the 'vod' benchmark type and the provided 5 second 'house\_ 1920x1080\_ 30.mkv' video file reference score.}}{41}{figure.7.1}% 
\contentsline {figure}{\numberline {7.2}{\ignorespaces Distribution of vBench scores in frequency polygons. Higher peaks represent more common scores. The columns separate the instance category, rows separate the cloud providers, while color distinguishes the number of vCPUs available in that instance. vBench benchmark was run using the 'vod' benchmark type and the provided 5 second 'house\_ 1920x1080\_ 30.mkv' video file reference score.}}{42}{figure.7.2}% 
\contentsline {figure}{\numberline {7.3}{\ignorespaces Optimal configurations suggested after convergence for Bayesian Optimization searches. Bayesian Optimization attempted to maximize the vBench 'vod' score divided by the configuration price. Prior function used was a Gaussian process, with Expected Improvement used as an Acquisition function. Searches were stopped at N $>$ 6 and EI $<$ 10\%, and the shown configuration was the instance with the best returned value.}}{44}{figure.7.3}% 
\contentsline {figure}{\numberline {7.4}{\ignorespaces Values, search costs and search times for different Bayesian Optimization searches. Single large outlier removed from search time graph from Single provider, 3 concurrent jobs. In single provider tests, only Google compute Engine was involved. Best values shows the values the search returned as a proportion of the optimal possible value the search could attain, calculated from the mean value available from jobs run on the best instance in the search space. Search time calculated by measuring the time between the first and last sample taken. Search cost taken by multiplying each job by that instance's hourly price and summing these values. 'Ping test' test type used latency of responses to a web-server, while other tests used a vBench benchmark.}}{46}{figure.7.4}% 
\contentsline {figure}{\numberline {7.5}{\ignorespaces Paths of example Bayesian Optimization jobs to optimize a vBench 'vod' score. Number an arrows show the progression of paths, with each points showing a different cloud configuration that was sampled. The y-axis shows the objective measure value returned by the sample. Colour shows cloud provider, either Amazon EC2 (aws) or Google compute engine (google).}}{47}{figure.7.5}% 
\addvspace {10\p@ }
